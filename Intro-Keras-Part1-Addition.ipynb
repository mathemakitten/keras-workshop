{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Keras - Teaching a Neural Network to Add \n",
    " \n",
    "This workshop is based on work created and shared by the Keras team at Google, and used according to terms described in The MIT License (MIT). \n",
    "\n",
    "Source: https://github.com/keras-team/keras/tree/master/examples\n",
    "\n",
    "In this section, we will teach a recurrent neural network how to successfully add without ever explicitly defining the addition function with sequence-to-sequence learning. ex. Input: \"535+61\" will produce Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, shown to increase performance in many tasks, as in the following papers: \n",
    "\n",
    "\"Learning to Execute\": http://arxiv.org/abs/1410.4615\n",
    "\"Sequence to Sequence Learning with Neural Networks\": http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "Two digits reversed:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\helen\\anaconda3\\lib\\site-packages (2.1.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras) (0.19.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras) (2.7.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras) (1.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras \n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the addition dataset\n",
    "\n",
    "The success of a machine learning model is fully dependent on the quality of data being fed into it. We're going to generate 50k examples of addition to use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "class CharacterTable(object):\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "# Use this to identify whether examples were correct or not (red = wrong, green = right)\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training data parameters \n",
    "\n",
    "You can adjust these parameters to generate more data or more complex addition examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# This step actually generates the data \n",
    "\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    \n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    \n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    \n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    \n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup machine learning \n",
    "\n",
    "We're going to split our created dataset into training and validation datasets to assess model performance. In industry, we often use an additional test set to assess model performance, and validation data is used for fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over\n",
    "\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by training a long-short term memory machine network (LSTM), which is a recurrent neural network made up of long-short term memory units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', # more on optimizers: https://keras.io/optimizers/\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start training! \n",
    "\n",
    "We're going to start compiling the model over 200 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 17s 368us/step - loss: 1.8873 - acc: 0.3210 - val_loss: 1.7929 - val_acc: 0.3427\n",
      "Q 229+89  T 318  \u001b[91m☒\u001b[0m 101 \n",
      "Q 0+74    T 74   \u001b[91m☒\u001b[0m 13  \n",
      "Q 56+26   T 82   \u001b[91m☒\u001b[0m 137 \n",
      "Q 967+733 T 1700 \u001b[91m☒\u001b[0m 1107\n",
      "Q 858+306 T 1164 \u001b[91m☒\u001b[0m 1107\n",
      "Q 495+481 T 976  \u001b[91m☒\u001b[0m 101 \n",
      "Q 15+171  T 186  \u001b[91m☒\u001b[0m 101 \n",
      "Q 983+547 T 1530 \u001b[91m☒\u001b[0m 1107\n",
      "Q 346+84  T 430  \u001b[91m☒\u001b[0m 137 \n",
      "Q 451+72  T 523  \u001b[91m☒\u001b[0m 131 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 343us/step - loss: 1.7326 - acc: 0.3624 - val_loss: 1.6721 - val_acc: 0.3821\n",
      "Q 78+653  T 731  \u001b[91m☒\u001b[0m 806 \n",
      "Q 6+55    T 61   \u001b[91m☒\u001b[0m 16  \n",
      "Q 978+70  T 1048 \u001b[91m☒\u001b[0m 909 \n",
      "Q 68+325  T 393  \u001b[91m☒\u001b[0m 389 \n",
      "Q 388+91  T 479  \u001b[91m☒\u001b[0m 902 \n",
      "Q 924+15  T 939  \u001b[91m☒\u001b[0m 502 \n",
      "Q 112+55  T 167  \u001b[91m☒\u001b[0m 222 \n",
      "Q 46+364  T 410  \u001b[91m☒\u001b[0m 469 \n",
      "Q 46+652  T 698  \u001b[91m☒\u001b[0m 666 \n",
      "Q 858+306 T 1164 \u001b[91m☒\u001b[0m 102 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 15s 333us/step - loss: 1.6006 - acc: 0.4008 - val_loss: 1.5311 - val_acc: 0.4240\n",
      "Q 713+22  T 735  \u001b[91m☒\u001b[0m 737 \n",
      "Q 696+90  T 786  \u001b[91m☒\u001b[0m 901 \n",
      "Q 914+86  T 1000 \u001b[91m☒\u001b[0m 101 \n",
      "Q 371+128 T 499  \u001b[91m☒\u001b[0m 787 \n",
      "Q 693+87  T 780  \u001b[91m☒\u001b[0m 901 \n",
      "Q 768+20  T 788  \u001b[91m☒\u001b[0m 877 \n",
      "Q 187+912 T 1099 \u001b[91m☒\u001b[0m 1017\n",
      "Q 246+375 T 621  \u001b[91m☒\u001b[0m 617 \n",
      "Q 930+731 T 1661 \u001b[91m☒\u001b[0m 1399\n",
      "Q 162+495 T 657  \u001b[91m☒\u001b[0m 617 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 17s 367us/step - loss: 1.4452 - acc: 0.4597 - val_loss: 1.3570 - val_acc: 0.4973\n",
      "Q 7+520   T 527  \u001b[91m☒\u001b[0m 521 \n",
      "Q 68+32   T 100  \u001b[91m☒\u001b[0m 13  \n",
      "Q 782+84  T 866  \u001b[91m☒\u001b[0m 833 \n",
      "Q 26+553  T 579  \u001b[91m☒\u001b[0m 610 \n",
      "Q 12+962  T 974  \u001b[91m☒\u001b[0m 901 \n",
      "Q 870+38  T 908  \u001b[91m☒\u001b[0m 891 \n",
      "Q 0+801   T 801  \u001b[91m☒\u001b[0m 880 \n",
      "Q 750+0   T 750  \u001b[91m☒\u001b[0m 771 \n",
      "Q 718+428 T 1146 \u001b[91m☒\u001b[0m 1106\n",
      "Q 99+742  T 841  \u001b[91m☒\u001b[0m 901 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 18s 404us/step - loss: 1.2859 - acc: 0.5243 - val_loss: 1.2281 - val_acc: 0.5409\n",
      "Q 6+684   T 690  \u001b[91m☒\u001b[0m 677 \n",
      "Q 2+699   T 701  \u001b[91m☒\u001b[0m 677 \n",
      "Q 329+460 T 789  \u001b[91m☒\u001b[0m 777 \n",
      "Q 18+37   T 55   \u001b[91m☒\u001b[0m 10  \n",
      "Q 421+929 T 1350 \u001b[91m☒\u001b[0m 1222\n",
      "Q 66+894  T 960  \u001b[91m☒\u001b[0m 977 \n",
      "Q 81+932  T 1013 \u001b[91m☒\u001b[0m 901 \n",
      "Q 0+468   T 468  \u001b[91m☒\u001b[0m 569 \n",
      "Q 30+968  T 998  \u001b[91m☒\u001b[0m 901 \n",
      "Q 931+47  T 978  \u001b[91m☒\u001b[0m 901 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 425us/step - loss: 1.1426 - acc: 0.5797 - val_loss: 1.0810 - val_acc: 0.6013\n",
      "Q 750+5   T 755  \u001b[92m☑\u001b[0m 755 \n",
      "Q 700+3   T 703  \u001b[91m☒\u001b[0m 700 \n",
      "Q 185+882 T 1067 \u001b[91m☒\u001b[0m 1056\n",
      "Q 97+810  T 907  \u001b[91m☒\u001b[0m 886 \n",
      "Q 367+611 T 978  \u001b[91m☒\u001b[0m 984 \n",
      "Q 171+61  T 232  \u001b[91m☒\u001b[0m 215 \n",
      "Q 68+9    T 77   \u001b[91m☒\u001b[0m 66  \n",
      "Q 9+865   T 874  \u001b[91m☒\u001b[0m 876 \n",
      "Q 770+253 T 1023 \u001b[91m☒\u001b[0m 1002\n",
      "Q 35+588  T 623  \u001b[91m☒\u001b[0m 620 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 18s 409us/step - loss: 1.0022 - acc: 0.6381 - val_loss: 0.9411 - val_acc: 0.6608\n",
      "Q 4+347   T 351  \u001b[91m☒\u001b[0m 344 \n",
      "Q 55+94   T 149  \u001b[91m☒\u001b[0m 144 \n",
      "Q 934+3   T 937  \u001b[91m☒\u001b[0m 934 \n",
      "Q 3+948   T 951  \u001b[91m☒\u001b[0m 943 \n",
      "Q 45+101  T 146  \u001b[91m☒\u001b[0m 151 \n",
      "Q 767+854 T 1621 \u001b[92m☑\u001b[0m 1621\n",
      "Q 49+245  T 294  \u001b[91m☒\u001b[0m 290 \n",
      "Q 147+51  T 198  \u001b[91m☒\u001b[0m 290 \n",
      "Q 829+49  T 878  \u001b[92m☑\u001b[0m 878 \n",
      "Q 87+799  T 886  \u001b[91m☒\u001b[0m 878 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 417us/step - loss: 0.8943 - acc: 0.6833 - val_loss: 0.8662 - val_acc: 0.6946\n",
      "Q 868+3   T 871  \u001b[91m☒\u001b[0m 870 \n",
      "Q 535+748 T 1283 \u001b[91m☒\u001b[0m 1288\n",
      "Q 964+777 T 1741 \u001b[91m☒\u001b[0m 1733\n",
      "Q 3+161   T 164  \u001b[91m☒\u001b[0m 160 \n",
      "Q 31+42   T 73   \u001b[91m☒\u001b[0m 70  \n",
      "Q 105+80  T 185  \u001b[92m☑\u001b[0m 185 \n",
      "Q 651+848 T 1499 \u001b[91m☒\u001b[0m 1406\n",
      "Q 5+723   T 728  \u001b[91m☒\u001b[0m 727 \n",
      "Q 549+429 T 978  \u001b[91m☒\u001b[0m 988 \n",
      "Q 87+519  T 606  \u001b[91m☒\u001b[0m 516 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 18s 398us/step - loss: 0.8193 - acc: 0.7134 - val_loss: 0.7904 - val_acc: 0.7253\n",
      "Q 335+579 T 914  \u001b[91m☒\u001b[0m 901 \n",
      "Q 56+732  T 788  \u001b[91m☒\u001b[0m 781 \n",
      "Q 264+73  T 337  \u001b[91m☒\u001b[0m 335 \n",
      "Q 875+45  T 920  \u001b[91m☒\u001b[0m 911 \n",
      "Q 909+399 T 1308 \u001b[91m☒\u001b[0m 1306\n",
      "Q 15+56   T 71   \u001b[91m☒\u001b[0m 86  \n",
      "Q 256+95  T 351  \u001b[91m☒\u001b[0m 355 \n",
      "Q 737+75  T 812  \u001b[91m☒\u001b[0m 811 \n",
      "Q 528+28  T 556  \u001b[91m☒\u001b[0m 550 \n",
      "Q 751+3   T 754  \u001b[91m☒\u001b[0m 756 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 419us/step - loss: 0.7476 - acc: 0.7401 - val_loss: 0.7148 - val_acc: 0.7496\n",
      "Q 137+46  T 183  \u001b[91m☒\u001b[0m 182 \n",
      "Q 15+525  T 540  \u001b[92m☑\u001b[0m 540 \n",
      "Q 903+6   T 909  \u001b[91m☒\u001b[0m 918 \n",
      "Q 5+749   T 754  \u001b[91m☒\u001b[0m 753 \n",
      "Q 8+951   T 959  \u001b[91m☒\u001b[0m 950 \n",
      "Q 657+30  T 687  \u001b[91m☒\u001b[0m 680 \n",
      "Q 389+858 T 1247 \u001b[91m☒\u001b[0m 1255\n",
      "Q 61+600  T 661  \u001b[91m☒\u001b[0m 662 \n",
      "Q 628+172 T 800  \u001b[91m☒\u001b[0m 703 \n",
      "Q 454+7   T 461  \u001b[91m☒\u001b[0m 460 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 420us/step - loss: 0.6282 - acc: 0.7777 - val_loss: 0.5448 - val_acc: 0.7992\n",
      "Q 467+12  T 479  \u001b[91m☒\u001b[0m 478 \n",
      "Q 14+72   T 86   \u001b[92m☑\u001b[0m 86  \n",
      "Q 2+855   T 857  \u001b[91m☒\u001b[0m 858 \n",
      "Q 66+140  T 206  \u001b[91m☒\u001b[0m 108 \n",
      "Q 869+959 T 1828 \u001b[91m☒\u001b[0m 1805\n",
      "Q 74+489  T 563  \u001b[91m☒\u001b[0m 562 \n",
      "Q 49+992  T 1041 \u001b[91m☒\u001b[0m 1030\n",
      "Q 110+692 T 802  \u001b[91m☒\u001b[0m 812 \n",
      "Q 950+31  T 981  \u001b[91m☒\u001b[0m 982 \n",
      "Q 12+38   T 50   \u001b[91m☒\u001b[0m 59  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 443us/step - loss: 0.4313 - acc: 0.8561 - val_loss: 0.3632 - val_acc: 0.8855\n",
      "Q 6+584   T 590  \u001b[92m☑\u001b[0m 590 \n",
      "Q 996+96  T 1092 \u001b[92m☑\u001b[0m 1092\n",
      "Q 230+9   T 239  \u001b[92m☑\u001b[0m 239 \n",
      "Q 9+458   T 467  \u001b[92m☑\u001b[0m 467 \n",
      "Q 76+34   T 110  \u001b[92m☑\u001b[0m 110 \n",
      "Q 977+89  T 1066 \u001b[92m☑\u001b[0m 1066\n",
      "Q 7+477   T 484  \u001b[92m☑\u001b[0m 484 \n",
      "Q 310+333 T 643  \u001b[91m☒\u001b[0m 634 \n",
      "Q 420+380 T 800  \u001b[91m☒\u001b[0m 701 \n",
      "Q 532+829 T 1361 \u001b[92m☑\u001b[0m 1361\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 414us/step - loss: 0.2878 - acc: 0.9243 - val_loss: 0.2411 - val_acc: 0.9443\n",
      "Q 353+708 T 1061 \u001b[92m☑\u001b[0m 1061\n",
      "Q 76+34   T 110  \u001b[92m☑\u001b[0m 110 \n",
      "Q 964+1   T 965  \u001b[92m☑\u001b[0m 965 \n",
      "Q 398+938 T 1336 \u001b[91m☒\u001b[0m 1335\n",
      "Q 93+473  T 566  \u001b[92m☑\u001b[0m 566 \n",
      "Q 347+462 T 809  \u001b[91m☒\u001b[0m 709 \n",
      "Q 29+88   T 117  \u001b[92m☑\u001b[0m 117 \n",
      "Q 186+448 T 634  \u001b[92m☑\u001b[0m 634 \n",
      "Q 464+46  T 510  \u001b[92m☑\u001b[0m 510 \n",
      "Q 37+96   T 133  \u001b[92m☑\u001b[0m 133 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 17s 380us/step - loss: 0.1900 - acc: 0.9611 - val_loss: 0.1675 - val_acc: 0.9639\n",
      "Q 606+541 T 1147 \u001b[91m☒\u001b[0m 1146\n",
      "Q 60+252  T 312  \u001b[92m☑\u001b[0m 312 \n",
      "Q 88+273  T 361  \u001b[92m☑\u001b[0m 361 \n",
      "Q 6+249   T 255  \u001b[92m☑\u001b[0m 255 \n",
      "Q 77+202  T 279  \u001b[92m☑\u001b[0m 279 \n",
      "Q 58+134  T 192  \u001b[92m☑\u001b[0m 192 \n",
      "Q 27+501  T 528  \u001b[92m☑\u001b[0m 528 \n",
      "Q 715+3   T 718  \u001b[92m☑\u001b[0m 718 \n",
      "Q 3+951   T 954  \u001b[92m☑\u001b[0m 954 \n",
      "Q 38+11   T 49   \u001b[92m☑\u001b[0m 49  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 19s 424us/step - loss: 0.1363 - acc: 0.9745 - val_loss: 0.1265 - val_acc: 0.9746\n",
      "Q 726+15  T 741  \u001b[92m☑\u001b[0m 741 \n",
      "Q 129+25  T 154  \u001b[92m☑\u001b[0m 154 \n",
      "Q 929+525 T 1454 \u001b[92m☑\u001b[0m 1454\n",
      "Q 83+260  T 343  \u001b[92m☑\u001b[0m 343 \n",
      "Q 11+745  T 756  \u001b[92m☑\u001b[0m 756 \n",
      "Q 5+40    T 45   \u001b[92m☑\u001b[0m 45  \n",
      "Q 976+931 T 1907 \u001b[91m☒\u001b[0m 1817\n",
      "Q 86+74   T 160  \u001b[92m☑\u001b[0m 160 \n",
      "Q 61+159  T 220  \u001b[92m☑\u001b[0m 220 \n",
      "Q 73+603  T 676  \u001b[92m☑\u001b[0m 676 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "13184/45000 [=======>......................] - ETA: 14s - loss: 0.1040 - acc: 0.9846"
     ]
    }
   ],
   "source": [
    "# Train the model each generation and show predictions against the validation dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    \n",
    "    # For each iteration, select 10 samples from the validation set at random so we can visualize errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
